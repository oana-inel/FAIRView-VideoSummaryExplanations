{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import csv\n",
    "import urllib\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# modify the line below and add the path to your google credentials json file\n",
    "# further information on how to generate such a json file: https://cloud.google.com/docs/authentication/getting-started#command-line\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = PLACEHOLDER_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# in this notebook we need two Google Cloud Storage buckets: https://cloud.google.com/storage/docs/creating-buckets\n",
    "# in the first bucket we have the videos\n",
    "# in the second bucket we store the labels extracted from the video frames\n",
    "\n",
    "# Replace all PLACEHOLDER_ variables with the variables you have created.\n",
    "def list_blobs_with_prefix(bucket_name, prefix, delimiter):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=prefix, delimiter=delimiter)\n",
    "\n",
    "    videos = []\n",
    "    for blob in blobs:\n",
    "        if not blob.name.endswith(\"/\"):\n",
    "            videos.append(\"gs://\" + bucket_name + \"/\" + blob.name)\n",
    "            \n",
    "    return videos\n",
    "            \n",
    "videos = list_blobs_with_prefix(PLACEHOLDER_BUCKET_NAME_VIDEOS, PLACEHOLDER_PREFIX, PLACEHOLDER_DELIMITER)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import videointelligence\n",
    "import csv\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Replace all PLACEHOLDER_ variables with the variables you have created.\n",
    "gcloud_bucket_name_frame = PLACEHOLDER_BUCKET_NAME_VIDEO_LABELS\n",
    "bucket_frame = storage_client.get_bucket(gcloud_bucket_name_frame)\n",
    "\n",
    "\"\"\" Detects labels given a GCS path. \"\"\"\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.enums.Feature.LABEL_DETECTION]\n",
    "\n",
    "mode = videointelligence.enums.LabelDetectionMode.SHOT_AND_FRAME_MODE\n",
    "config = videointelligence.types.LabelDetectionConfig(\n",
    "    label_detection_mode=mode)\n",
    "context = videointelligence.types.VideoContext(\n",
    "    label_detection_config=config)\n",
    "\n",
    "for video in videos:\n",
    "    \n",
    "    videoTitle = video.split(\"/\")[-1]\n",
    "\n",
    "    names = [\"storageLink\",\"label\",\"time_offset\",\"confidence\",\"type\", \"label_entity_id\", \"type_id\"]\n",
    "    with open(\"../data/labels_video_frames/\" + videoTitle + \".csv\", \"w\" ) as outSentences:\n",
    "        writer = csv.writer( outSentences )\n",
    "        writer.writerow(names)\n",
    "\n",
    "    operation = video_client.annotate_video(\n",
    "        video, features=features, video_context=context)\n",
    "    \n",
    "    # Process frame level label annotations\n",
    "    frame_labels = result.annotation_results[0].frame_label_annotations\n",
    "    for i, frame_label in enumerate(frame_labels):\n",
    "        categories = []\n",
    "        category_ids = []\n",
    "        for category_entity in frame_label.category_entities:\n",
    "            categories.append(category_entity.description)\n",
    "            category_ids.append(category_entity.entity_id)\n",
    "\n",
    "        for i, frame in enumerate(frame_label.frames):\n",
    "            time_offset = (frame.time_offset.seconds + frame.time_offset.nanos / 1e9)\n",
    "            confidence = frame.confidence\n",
    "\n",
    "            row = []\n",
    "            row.append(videoTitle[0:-4])\n",
    "            row.append(frame_label.entity.description)\n",
    "            row.append(time_offset)\n",
    "            row.append(confidence)\n",
    "            row.append(\", \".join(categories))\n",
    "            row.append(frame_label.entity.entity_id)\n",
    "            row.append(\", \".join(category_ids))\n",
    "\n",
    "            with open(\"../data/labels_video_frames/\" + videoTitle + \".csv\", \"a\" ) as outSentences:\n",
    "                writer = csv.writer( outSentences )\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    blob = bucket_frame.blob(\"\" + videoTitle + \".csv\")\n",
    "    blob.upload_from_filename(\"../data/labels_video_frames/\" + videoTitle + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
