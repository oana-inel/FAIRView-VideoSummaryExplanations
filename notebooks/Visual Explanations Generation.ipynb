{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import mlab\n",
    "import string\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import ast\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Key Concepts of the Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the video dataset\n",
    "dataset = pd.read_csv(\"../data/video_dataset_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import six\n",
    "import statistics\n",
    "\n",
    "\n",
    "names = [\"videoId\",\"no_videoframes_labels\", \"videoframes_labels\", \"no_videoframes_labels_pos\", \"videoframes_labels_pos\",\n",
    "         \"no_videoframes_labels_median\", \"videoframes_labels_median\", \n",
    "         \"no_videoframes_labels_avg\", \"videoframes_labels_avg\", \n",
    "         \"no_videoframes_labels_stdev\", \"videoframes_labels_stdev\",\n",
    "         \"no_videoframes_labels_30\", \"videoframes_labels_30\", \"no_entities\", \"entities\", \n",
    "         \"no_entities_noother\", \"entities_noother\", \"no_vision\", \"vision_labels\",\n",
    "         \"no_final_concepts\", \"final_concepts\", \n",
    "         \"final_concepts_counts\", \"final_concepts_freqs\"]\n",
    "\n",
    "with open(\"../data/key_concepts_videos/video_concepts_overview.csv\", \"w\" ) as outSentences:\n",
    "    writer = csv.writer( outSentences )\n",
    "    writer.writerow(names)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    videoid = dataset[\"youtubeLink\"].iloc[i].split(\"=\")[-1]\n",
    "    \n",
    "    row = []\n",
    "    row.append(videoid)\n",
    "\n",
    "    labels = pd.read_csv(\"../data/labels_video_frames/\" + videoid + \".mp4.csv\")\n",
    "    \n",
    "    uniqueLabels = list(set(labels[\"label_lemma\"]))\n",
    "    videolabels_no_current = len(list(set(labels[\"label_lemma\"])))\n",
    "    videolabels_text_current = (\"_###_\").join(list(set(labels[\"label_lemma\"])))\n",
    "    \n",
    "    row.append(videolabels_no_current)\n",
    "    row.append(videolabels_text_current)\n",
    " \n",
    "    max_duration = dataset['duration'].iloc[i]\n",
    "    \n",
    "    part1_vid = max_duration / 3\n",
    "    part2_vid = part1_vid * 2\n",
    "    part3_vid = max_duration\n",
    "    \n",
    "    vid_part1 = labels[labels[\"time_offset\"] <= part1_vid]\n",
    "    vid_part2 = labels[(labels[\"time_offset\"] > part1_vid) & (labels[\"time_offset\"] <= part2_vid)]\n",
    "    vid_part3 = labels[labels[\"time_offset\"] > part2_vid]\n",
    "    \n",
    "    pos_labels = []\n",
    "    pos_times = []\n",
    "    for label in uniqueLabels:\n",
    "        if label in list(set(vid_part1[\"label_lemma\"])) and label in list(set(vid_part2[\"label_lemma\"])) and label in list(set(vid_part3[\"label_lemma\"])):\n",
    "            pos_labels.append(label)\n",
    "            pos_times.append(len(labels[labels[\"label_lemma\"] == label]))\n",
    "            \n",
    "    row.append(len(pos_labels))\n",
    "    row.append((\"###\").join(pos_labels))\n",
    "    \n",
    "    if len(pos_labels) != 0:\n",
    "        median_value = statistics.median(pos_times)\n",
    "        average_value = sum(pos_times) / len(pos_times)\n",
    "        std = statistics.stdev(pos_times)\n",
    "    else:\n",
    "        median_value = 0\n",
    "        average_value = 0\n",
    "        std = 0\n",
    "    \n",
    "    percentage = dataset['duration'].iloc[i] * 30 / 100\n",
    "    \n",
    "    averageLabels = []\n",
    "    medianLabels = []\n",
    "    stdevLabels = []\n",
    "    percentageLabels = []\n",
    "    for label in uniqueLabels:\n",
    "        if len(labels[labels[\"label_lemma\"] == label]) > median_value:\n",
    "            medianLabels.append(label)\n",
    "        if len(labels[labels[\"label_lemma\"] == label]) > average_value:\n",
    "            averageLabels.append(label)\n",
    "        if len(labels[labels[\"label_lemma\"] == label]) > std + average_value:\n",
    "            stdevLabels.append(label)\n",
    "        if len(labels[labels[\"label_lemma\"] == label]) > percentage:\n",
    "            percentageLabels.append(label)\n",
    "    \n",
    "    row.append(len(medianLabels))\n",
    "    row.append((\"###\").join(medianLabels))\n",
    "\n",
    "    row.append(len(averageLabels))\n",
    "    row.append((\"###\").join(averageLabels))\n",
    "    \n",
    "    row.append(len(stdevLabels))\n",
    "    row.append((\"###\").join(stdevLabels))\n",
    "    \n",
    "    row.append(len(percentageLabels))\n",
    "    row.append((\"###\").join(percentageLabels))\n",
    "    \n",
    "  \n",
    "    entities = pd.read_csv(\"../data/named_entities_subtitles/\" + videoid + \".mp4.csv\")\n",
    "        \n",
    "    videolabels_no_current = len(list(set(entities[\"entity_lemma\"])))\n",
    "    videolabels_text_current = (\"_###_\").join(list(set(entities[\"entity_lemma\"])))\n",
    "    \n",
    "    row.append(videolabels_no_current)\n",
    "    row.append(videolabels_text_current)\n",
    "    \n",
    "    noother = []\n",
    "    for label in list(set(entities[\"entity_lemma\"])):\n",
    "        subset = entities[entities[\"entity_lemma\"] == label]\n",
    "        if subset[\"type_v3\"].iloc[0] != \"OTHER\":\n",
    "            noother.append(label)\n",
    "    \n",
    "    row.append(len(noother))\n",
    "    row.append((\"###\").join(noother))    \n",
    "    \n",
    "    lst3 = [value for value in pos_labels if value in medianLabels] \n",
    "    row.append(len(lst3))\n",
    "    row.append((\"###\").join(lst3))    \n",
    "    \n",
    "    lst4 = set(lst3).union(set(noother)) \n",
    "    row.append(len(list(lst4)))\n",
    "    row.append((\"###\").join(list(lst4))) \n",
    "    \n",
    "    frequencyE = []\n",
    "    frequencyL = []\n",
    "    \n",
    "    for tag in list(lst4):\n",
    "        subset = entities[(entities[\"entity_lemma\"] == tag) & (entities[\"type_v3\"] != \"OTHER\")]\n",
    "        \n",
    "        if (len(subset) > 0): \n",
    "            frequencyE.append((tag, len(subset)))\n",
    "        else:\n",
    "            subset = labels[labels[\"label_lemma\"] == tag]\n",
    "            frequencyL.append((tag, len(subset)))\n",
    "    \n",
    "    frequencyEE = []\n",
    "    frequencyLL = []\n",
    "    \n",
    "    if len(frequencyE) != 0:\n",
    "        maxe = max(frequencyE,key=lambda x:x[1])\n",
    "    else:\n",
    "        maxe = 0\n",
    "    if len(frequencyL) != 0:\n",
    "        maxl = max(frequencyL,key=lambda x:x[1])\n",
    "    else:\n",
    "        maxl = 0\n",
    "    \n",
    "    for tag in list(lst4):\n",
    "        subset = entities[entities[\"entity_lemma\"] == tag]\n",
    "        \n",
    "        if (len(subset) != 0): \n",
    "            frequencyEE.append((tag, len(subset)/maxe[1] * 1.0))\n",
    "        else:\n",
    "            subset = labels[labels[\"label_lemma\"] == tag]\n",
    "            frequencyLL.append((tag, len(subset)/maxl[1] * 1.0))\n",
    "    \n",
    "    allTuples = frequencyE\n",
    "    for tup in frequencyL:\n",
    "        allTuples.append(tup)\n",
    "        \n",
    "    row.append(allTuples)\n",
    "    \n",
    "    allTuples = frequencyEE\n",
    "    for tup in frequencyLL:\n",
    "        allTuples.append(tup)\n",
    "        \n",
    "    row.append(allTuples)\n",
    "    \n",
    "    with open(\"../data/key_concepts_videos/video_concepts_overview.csv\", \"a\" ) as outSentences:\n",
    "        writer = csv.writer( outSentences )\n",
    "        writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Summary Wordcloud Visual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "def grey_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return \"hsl(120, 100%%, %d%%)\" % random.randint(25, 25)\n",
    "\n",
    "# the file below contains the key concepts we identified in the original video\n",
    "selected_tags = pd.read_csv(\"../data/key_concepts_videos/video_concepts_overview.csv\")\n",
    "types_of_summary = [\"___10___aq\", \"___20___aq\", \"___10___nq\", \"___20___nq\"]\n",
    "\n",
    "for j in range(len(selected_tags)):\n",
    "    videoId = selected_tags[\"videoId\"].iloc[j]\n",
    "    \n",
    "    for type_sum in types_of_summary:\n",
    "        # we read now the concepts from the video summaries\n",
    "        entity_data = pd.read_csv(\"../data/concepts_video_summaries/entities_\" + videoId + type_sum + \".csv\")\n",
    "        label_data = pd.read_csv(\"../data/concepts_video_summaries/labels_\" + videoId + type_sum + \".csv\")\n",
    "    \n",
    "        subset = selected_tags[selected_tags[\"videoId\"] == videoId]\n",
    "        tags_in_subset = subset[\"final_concepts\"].iloc[0].split(\"###\")\n",
    "                           \n",
    "        \n",
    "        word_cloud_dict1 = Counter(list(entity_data[\"entity_lemma\"]))\n",
    "        for key in word_cloud_dict1:\n",
    "            word_cloud_dict1[key] /= word_cloud_dict1.most_common(1)[0][1]\n",
    "\n",
    "        word_cloud_dict2 = Counter(list(label_data[\"label_lemma\"]))\n",
    "        for key in word_cloud_dict2:\n",
    "            word_cloud_dict2[key] /= word_cloud_dict2.most_common(1)[0][1]\n",
    "\n",
    "        for key in word_cloud_dict2:\n",
    "            if key not in word_cloud_dict1:\n",
    "                word_cloud_dict1[key] = word_cloud_dict2[key]\n",
    "\n",
    "\n",
    "        word_cloud_dict = Counter()\n",
    "        for key in word_cloud_dict1:\n",
    "            if key in tags_in_subset:\n",
    "                word_cloud_dict[key] = word_cloud_dict1[key]\n",
    "                \n",
    "\n",
    "        wordcloud = WordCloud(width = 1000, height = 500, background_color=\"white\").generate_from_frequencies(word_cloud_dict)\n",
    "\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3), interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../data/visual_explanations/\" + videoId + type_sum + '_summary_wordcloud.png', format='png', dpi=1000, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Overlap Wordcloud Visual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "def grey_color_func(word, **kwargs):\n",
    "    if word in overlapping_words:\n",
    "        color = 'green' \n",
    "    else:\n",
    "        color = 'purple'\n",
    "    return color\n",
    "\n",
    "# the file below contains the key concepts we identified in the original video\n",
    "selected_tags = pd.read_csv(\"../data/key_concepts_videos/video_concepts_overview.csv\")\n",
    "types_of_summary = [\"___10___aq\", \"___20___aq\", \"___10___nq\", \"___20___nq\"]\n",
    "\n",
    "for j in range(len(selected_tags)):\n",
    "    videoId = selected_tags[\"videoId\"].iloc[j]\n",
    "\n",
    "    for type_sum in types_of_summary:\n",
    "\n",
    "        # we read now the concepts from the video summaries\n",
    "        entity_data = pd.read_csv(\"../data/concepts_video_summaries/entities_\" + videoId + type_sum + \".csv\")\n",
    "        label_data = pd.read_csv(\"../data/concepts_video_summaries/labels_\" + videoId + type_sum + \".csv\")\n",
    "    \n",
    "        subset = selected_tags[selected_tags[\"videoId\"] == videoId]\n",
    "        tags_in_subset = subset[\"final_concepts\"].iloc[0].split(\"###\")\n",
    "\n",
    "        word_cloud_dict1 = Counter(list(entity_data[\"entity_lemma\"]))\n",
    "        for key in word_cloud_dict1:\n",
    "            word_cloud_dict1[key] /= word_cloud_dict1.most_common(1)[0][1]\n",
    "\n",
    "        word_cloud_dict2 = Counter(list(label_data[\"label_lemma\"]))\n",
    "        for key in word_cloud_dict2:\n",
    "            word_cloud_dict2[key] /= word_cloud_dict2.most_common(1)[0][1]\n",
    "\n",
    "        for key in word_cloud_dict2:\n",
    "            if key not in word_cloud_dict1:\n",
    "                word_cloud_dict1[key] = word_cloud_dict2[key]\n",
    "\n",
    "        overlapping_words = []\n",
    "        for key in word_cloud_dict1:\n",
    "            if key in tags_in_subset:\n",
    "                overlapping_words.append(key)\n",
    "\n",
    "        listOfWords = ast.literal_eval(subset[\"final_concepts_freqs\"].iloc[0])\n",
    "\n",
    "        word_cloud_dict = Counter()\n",
    "        for key in listOfWords:\n",
    "            word_cloud_dict[key[0]] = key[1]\n",
    "\n",
    "        \n",
    "        wordcloud = WordCloud(width = 1000, height = 500, background_color=\"white\").generate_from_frequencies(word_cloud_dict)\n",
    "\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.imshow(wordcloud.recolor(color_func=grey_color_func, random_state=3), interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../data/visual_explanations/\" + videoId + type_sum + '_overlap_wordcloud.png', format='png', dpi=1000, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Overlap Fraction Visual Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grey_color_func(word, **kwargs):\n",
    "    if word in overlapping_words:\n",
    "        color = 'green' \n",
    "    else:\n",
    "        color = 'purple'\n",
    "    return color\n",
    "\n",
    "# the file below contains the key concepts we identified in the original video\n",
    "selected_tags = pd.read_csv(\"../data/key_concepts_videos/video_concepts_overview.csv\")\n",
    "types_of_summary = [\"___10___aq\", \"___20___aq\", \"___10___nq\", \"___20___nq\"]\n",
    "\n",
    "for j in range(len(selected_tags)):\n",
    "    videoId = selected_tags[\"videoId\"].iloc[j]\n",
    "    \n",
    "\n",
    "    for type_sum in types_of_summary:\n",
    "\n",
    "        # we read now the concepts from the video summaries\n",
    "        entity_data = pd.read_csv(\"../data/concepts_video_summaries/entities_\" + videoId + type_sum + \".csv\")\n",
    "        label_data = pd.read_csv(\"../data/concepts_video_summaries/labels_\" + videoId + type_sum + \".csv\")\n",
    "    \n",
    "        subset = selected_tags[selected_tags[\"videoId\"] == videoId]\n",
    "        tags_in_subset = subset[\"final_concepts\"].iloc[0].split(\"###\")\n",
    "\n",
    "        word_cloud_dict1 = Counter(list(entity_data[\"entity_lemma\"]))\n",
    "        for key in word_cloud_dict1:\n",
    "            word_cloud_dict1[key] /= word_cloud_dict1.most_common(1)[0][1]\n",
    "\n",
    "        word_cloud_dict2 = Counter(list(label_data[\"label_lemma\"]))\n",
    "        for key in word_cloud_dict2:\n",
    "            word_cloud_dict2[key] /= word_cloud_dict2.most_common(1)[0][1]\n",
    "\n",
    "        for key in word_cloud_dict2:\n",
    "            if key not in word_cloud_dict1:\n",
    "                word_cloud_dict1[key] = word_cloud_dict2[key]\n",
    "\n",
    "        overlapping_words = []\n",
    "        for key in word_cloud_dict1:\n",
    "            if key in tags_in_subset:\n",
    "                overlapping_words.append(key)\n",
    "\n",
    "\n",
    "        listOfWords = ast.literal_eval(subset[\"final_concepts_freqs\"].iloc[0])\n",
    "\n",
    "        word_cloud_dict = Counter()\n",
    "        for key in listOfWords:\n",
    "            word_cloud_dict[key[0]] = key[1]\n",
    "\n",
    "\n",
    "        # The slices will be ordered and plotted counter-clockwise.\n",
    "        sizes = [len(overlapping_words) * 100 / len(listOfWords), 100 - (len(overlapping_words) * 100 / len(listOfWords))]\n",
    "\n",
    "        labels = [str(round(len(overlapping_words) * 100 / len(listOfWords))) + '% of the video concepts \\n are covered by \\n the video summary', str(round(100 - (len(overlapping_words) * 100 / len(listOfWords)))) + '% of the video concepts \\n are not covered by \\n the video summary']\n",
    "        colors = ['green', 'purple']\n",
    "        explode = (0, 1)  # explode a slice if required\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 3), subplot_kw=dict(aspect=\"equal\"))\n",
    "        \n",
    "        wedges, texts = ax.pie(sizes, colors=colors, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "        kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "                  bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "        for i, p in enumerate(wedges):\n",
    "            ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "            y = np.sin(np.deg2rad(ang))\n",
    "            x = np.cos(np.deg2rad(ang))\n",
    "            horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "            connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "            kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "            ax.annotate(labels[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n",
    "                        horizontalalignment=horizontalalignment, **kw)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"../data/visual_explanations/\" + videoId + type_sum + '_overlap_fraction.png', format='png', dpi=1000, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Combined Wordcloud and Fraction Visual Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "# the file below contains the key concepts we identified in the original video\n",
    "selected_tags = pd.read_csv(\"../data/key_concepts_videos/video_concepts_overview.csv\")\n",
    "types_of_summary = [\"___10___aq\", \"___20___aq\", \"___10___nq\", \"___20___nq\"]\n",
    "\n",
    "for j in range(len(selected_tags)):\n",
    "    videoId = selected_tags[\"videoId\"].iloc[j]\n",
    "    \n",
    "    for type_sum in types_of_summary:\n",
    "        im1 = Image.open(\"../data/visual_explanations/\" + videoId + type_sum + '_overlap_wordcloud.png')\n",
    "        im2 = Image.open(\"../data/visual_explanations/\" + videoId + type_sum + '_overlap_fraction.png')\n",
    "        get_concat_v(im1, im2).save(\"../data/visual_explanations/\" + videoId + type_sum + '_combined_wordcloud_and_fraction.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
